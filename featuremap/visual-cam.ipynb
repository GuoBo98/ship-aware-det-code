{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "# import torch\n",
    "from skimage import io\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import mmcv\n",
    "import torch\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.cnn import fuse_conv_bn\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "from mmcv.runner import (get_dist_info, init_dist, load_checkpoint,\n",
    "                         wrap_fp16_model)\n",
    "\n",
    "from mmdet.apis import multi_gpu_test, single_gpu_test\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            )\n",
    "from mmdet.models import build_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile('/data2/guobo/01_SHIPRSDET/TrainTestv2/work_dirs/v1307_roitrans_r50_obbGRoI_noBN_noPre/v1307_roitrans_r50_obbGRoI_noBN_noPre.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 10:09:44,454 - mmdet - INFO - load model from: torchvision://resnet50\n",
      "2022-04-21 10:09:44,457 - mmdet - INFO - load checkpoint from torchvision path: torchvision://resnet50\n",
      "2022-04-21 10:09:44,801 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /data2/guobo/01_SHIPRSDET/TrainTestv2/work_dirs/v1307_roitrans_r50_obbGRoI_noBN_noPre/epoch_69.pth\n"
     ]
    }
   ],
   "source": [
    "checkpoint = load_checkpoint(model, \"/data2/guobo/01_SHIPRSDET/TrainTestv2/work_dirs/v1307_roitrans_r50_obbGRoI_noBN_noPre/epoch_69.pth\", map_location='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.CLASSES = checkpoint['meta']['CLASSES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "    dataset,\n",
    "    samples_per_gpu=1,\n",
    "    workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "    dist=False,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, t in enumerate(data_loader):\n",
    "    tmp = {}\n",
    "    tmp['img'] = t['img']\n",
    "    tmp['img_metas'] = t['img_metas'][0].data[0]\n",
    "    data.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': [tensor([[[[-0.1314, -0.2684, -0.1999,  ..., -0.9534, -0.9534, -0.9534],\n",
       "            [-0.0972, -0.1486, -0.0801,  ..., -0.9534, -0.9534, -0.9534],\n",
       "            [-0.0116, -0.0116, -0.0116,  ..., -0.9534, -0.9534, -0.9534],\n",
       "            ...,\n",
       "            [ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056],\n",
       "            [ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056],\n",
       "            [ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056]],\n",
       "  \n",
       "           [[ 0.2752,  0.1702,  0.2227,  ..., -0.5476, -0.5476, -0.5476],\n",
       "            [ 0.3102,  0.2752,  0.3102,  ..., -0.5476, -0.5476, -0.5476],\n",
       "            [ 0.3803,  0.3803,  0.3803,  ..., -0.5476, -0.5476, -0.5476],\n",
       "            ...,\n",
       "            [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
       "            [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
       "            [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049]],\n",
       "  \n",
       "           [[ 0.4265,  0.3568,  0.3916,  ..., -0.2707, -0.2707, -0.2707],\n",
       "            [ 0.4439,  0.4265,  0.4439,  ..., -0.2707, -0.2707, -0.2707],\n",
       "            [ 0.5485,  0.5311,  0.5136,  ..., -0.2707, -0.2707, -0.2707],\n",
       "            ...,\n",
       "            [ 0.0082,  0.0082,  0.0082,  ...,  0.0082,  0.0082,  0.0082],\n",
       "            [ 0.0082,  0.0082,  0.0082,  ...,  0.0082,  0.0082,  0.0082],\n",
       "            [ 0.0082,  0.0082,  0.0082,  ...,  0.0082,  0.0082,  0.0082]]]])],\n",
       " 'img_metas': [{'filename': '/data2/guobo/01_SHIPRSDET/ShipDetv2/dota/split_ss_1024/val/images/100000920_0001.png',\n",
       "   'ori_filename': '100000920_0001.png',\n",
       "   'ori_shape': (1024, 1024, 3),\n",
       "   'img_shape': (1024, 1024, 3),\n",
       "   'pad_shape': (1024, 1024, 3),\n",
       "   'scale_factor': array([1., 1., 1., 1.], dtype=float32),\n",
       "   'h_flip': False,\n",
       "   'v_flip': False,\n",
       "   'angle': 0,\n",
       "   'matrix': array([[1., 0., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 0., 1.]]),\n",
       "   'rotate_after_flip': True,\n",
       "   'img_norm_cfg': {'mean': array([123.675, 116.28 , 103.53 ], dtype=float32),\n",
       "    'std': array([58.395, 57.12 , 57.375], dtype=float32),\n",
       "    'to_rgb': True}}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg.nms_pre = 1000\n",
    "# cfg.min_bbox_size = 1\n",
    "# cfg.nms_thr = 10\n",
    "# cfg.nms_post = 1000\n",
    "test_cfg = model.rpn_head.test_cfg\n",
    "\n",
    "# img_metas = data['img_metas']\n",
    "####################################################################################3\n",
    "# 此處重寫了rpn_head.get_bboxes，因爲原函數使用detach把gradients的backprop刪了無法backward（）\n",
    "#######################################################################################\n",
    "\n",
    "def get_bboxes_tmp(rpn_outs, img_metas, test_cfg):\n",
    "    \n",
    "    with_nms = False\n",
    "    rescale = False\n",
    "    cls_scores = rpn_outs[0]\n",
    "    bbox_preds = rpn_outs[1]\n",
    "\n",
    "    num_levels = len(cls_scores)\n",
    "\n",
    "    device = cls_scores[0].device\n",
    "    featmap_sizes = [cls_scores[i].shape[-2:] for i in range(num_levels)]\n",
    "    mlvl_anchors = model.rpn_head.anchor_generator.grid_anchors(\n",
    "        featmap_sizes, device=device)\n",
    "\n",
    "    result_list = []\n",
    "    for img_id in range(len(img_metas)):\n",
    "        cls_score_list = [\n",
    "            cls_scores[i][img_id] for i in range(num_levels) # 此處不再使用detach()\n",
    "        ]\n",
    "        bbox_pred_list = [\n",
    "            bbox_preds[i][img_id] for i in range(num_levels) # 此處不再使用detach()\n",
    "        ]\n",
    "        img_shape = img_metas[img_id]['img_shape']\n",
    "        scale_factor = img_metas[img_id]['scale_factor']\n",
    "\n",
    "        if with_nms:\n",
    "            # some heads don't support with_nms argument\n",
    "            proposals = model.rpn_head._get_bboxes_single(cls_score_list,\n",
    "                                                bbox_pred_list,\n",
    "                                                mlvl_anchors, img_shape,\n",
    "                                                scale_factor, test_cfg, rescale)\n",
    "        else:\n",
    "            proposals = model.rpn_head._get_bboxes_single(cls_score_list,\n",
    "                                                bbox_pred_list,\n",
    "                                                mlvl_anchors, img_shape,\n",
    "                                                scale_factor, test_cfg, rescale)\n",
    "        result_list.append(proposals)\n",
    "    \n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM(object):\n",
    "    \"\"\"\n",
    "    1: 网络不更新梯度,输入需要梯度更新\n",
    "    2: 使用目标类别的得分做反向传播\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, net, layer_name):\n",
    "        self.net = net\n",
    "        self.layer_name = layer_name\n",
    "        self.feature = None\n",
    "        self.gradient = None\n",
    "        self.net.eval()\n",
    "        self.handlers = []\n",
    "        self._register_hook()\n",
    "\n",
    "    def _get_features_hook(self, module, input, output):\n",
    "        self.feature = output\n",
    "        # print(\"feature shape:{}\".format(output.size()))\n",
    "\n",
    "    def _get_grads_hook(self, module, input_grad, output_grad):\n",
    "        \"\"\"\n",
    "\n",
    "        :param input_grad: tuple, input_grad[0]: None\n",
    "                                   input_grad[1]: weight\n",
    "                                   input_grad[2]: bias\n",
    "        :param output_grad:tuple,长度为1\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.gradient = output_grad[0]\n",
    "        # print('gradient:', self.gradient)\n",
    "\n",
    "    def _register_hook(self):\n",
    "        for (name, module) in self.net.named_modules():\n",
    "            if name == self.layer_name:\n",
    "                self.handlers.append(module.register_forward_hook(self._get_features_hook))\n",
    "                self.handlers.append(module.register_backward_hook(self._get_grads_hook))\n",
    "#         module = self.net.rpn.head.bbox_pred\n",
    "#         self.handlers.append(module.register_forward_hook(self._get_features_hook))\n",
    "#         self.handlers.append(module.register_backward_hook(self._get_grads_hook))\n",
    "            \n",
    "                # print(self.handlers)\n",
    "\n",
    "    def remove_handlers(self):\n",
    "        for handle in self.handlers:\n",
    "            handle.remove()\n",
    "\n",
    "    def __call__(self, inputs, index=0):\n",
    "        \"\"\"\n",
    "\n",
    "        :param inputs: {\"image\": [C,H,W], \"height\": height, \"width\": width}\n",
    "        :param index: 第几个边框\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.net.zero_grad()\n",
    "        # output = self.net([inputs])\n",
    "        x = self.net.extract_feat(inputs['img'][0])\n",
    "        rpn_outs = self.net.rpn_head(x)\n",
    "        result_list = get_bboxes_tmp(rpn_outs,inputs['img_metas'],self.net.rpn_head.test_cfg)\n",
    "        res= self.net.roi_head.simple_test_bboxes(\n",
    "            x, inputs['img_metas'], result_list, self.net.roi_head.test_cfg, rescale=True)\n",
    "        # print(output)\n",
    "        score = res[0][0][index][4]\n",
    "        # proposal_idx = output[0]['labels'][index]  # box来自第几个proposal\n",
    "        # print(score)\n",
    "        score.backward()\n",
    "        # print('gradient:', self.gradient)\n",
    "\n",
    "        # gradient = self.gradient[proposal_idx].cpu().data.numpy()  # [C,H,W]\n",
    "        gradient = self.gradient.cpu().data.numpy().squeeze()\n",
    "        \n",
    "        weight = np.mean(gradient, axis=(1, 2))  # [C]\n",
    "\n",
    "        # feature = self.feature[proposal_idx].cpu().data.numpy()  # [C,H,W]\n",
    "        feature = self.feature.cpu().data.numpy().squeeze()\n",
    "\n",
    "        cam = feature * weight[:, np.newaxis, np.newaxis]  # [C,H,W]\n",
    "        # print(cam.shape)\n",
    "        cam = np.sum(cam, axis=0)  # [H,W]\n",
    "        cam = np.maximum(cam, 0)  # ReLU\n",
    "\n",
    "        # 数值归一化\n",
    "        cam -= np.min(cam)\n",
    "        cam /= np.max(cam)\n",
    "        # resize to 224*224\n",
    "        # box = output[0]['instances'].pred_boxes.tensor[index].detach().numpy().astype(np.int32)\n",
    "        box = res[0][0][index][:-1].detach().numpy().astype(np.int32)\n",
    "        x1, y1, x2, y2 = box\n",
    "        \n",
    "        # cam = cv2.resize(cam, (x2 - x1, y2 - y1))\n",
    "        # cam = cv2.resize(cam, (y2 - y1, x2 - x1)).T\n",
    "        # print(cam.shape)\n",
    "\n",
    "        # class_id = output[0]['instances'].pred_classes[index].detach().numpy()\n",
    "        class_id = res[1][0][index].detach().numpy()\n",
    "        plt.imshow(cam)\n",
    "        return cam, box, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam = GradCAM(model, 'backbone.layer4.2.conv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'RoITransRoIHead' object has no attribute 'simple_test_bboxes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7383/3186621010.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_7383/3961183540.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, index)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mrpn_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mresult_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bboxes_tmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrpn_outs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_metas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         res= self.net.roi_head.simple_test_bboxes(\n\u001b[0m\u001b[1;32m     60\u001b[0m             x, inputs['img_metas'], result_list, self.net.roi_head.test_cfg, rescale=True)\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/obbdetection/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    770\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 772\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'RoITransRoIHead' object has no attribute 'simple_test_bboxes'"
     ]
    }
   ],
   "source": [
    "mask, box, class_id = grad_cam(data[0],0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c154c85826733772be66802e27878213c071c4692592edc31c47870f03564cd2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('obbdetection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
